Monitorare il consumo delle risorse e le prestazioni delle applicazioni è essenziale per garantire il corretto funzionamento di un cluster Kubernetes. Questo include il monitoraggio a livello di nodi e pod, ma anche l'analisi delle metriche di utilizzo di risorse come CPU, memoria, rete e disco.

Per capire meglio, possiamo distinguere tra due livelli di monitoraggio:

- **Livello dei nodi**: È utile sapere quanti nodi ci sono nel cluster, se sono tutti in salute e come stanno performando in termini di utilizzo delle risorse. Ad esempio, puoi monitorare quanta CPU o memoria viene utilizzata su ciascun nodo.

- **Livello dei pod**: Kubernetes gestisce le applicazioni tramite pod, quindi è fondamentale tenere traccia del loro numero e delle loro prestazioni, come il consumo di CPU e memoria.


***
## Metrics Server

Kubernetes non include una soluzione completa di monitoraggio “out-of-the-box”, ma ci sono strumenti open-source che possono aiutarti. Tra questi, il Metrics Server è quello consigliato per un uso di base e viene spesso richiesto nella certificazione Kubernetes Developer.

Il Metrics Server nasce come una versione semplificata di un vecchio progetto chiamato Heapster, ormai deprecato. Si tratta di una soluzione leggera che raccoglie metriche dai nodi e dai pod, le aggrega e le conserva **in memoria**. È importante sottolineare che il Metrics Server non salva i dati su disco, quindi non puoi consultare metriche storiche. Per analisi più avanzate e storiche, potresti considerare strumenti come **Prometheus** o **Elastic Stack**.


### 1. Come funziona il Metrics Server
Ogni nodo Kubernetes esegue un componente chiamato **kubelet**, responsabile di ricevere le istruzioni dall’API server di Kubernetes e di avviare i pod sul nodo. All’interno del kubelet c’è un sottocomponente chiamato **cAdvisor (Container Advisor)**, che raccoglie le metriche sulle prestazioni dei container e le espone tramite l’API del kubelet. Il Metrics Server utilizza queste informazioni per costruire una panoramica delle prestazioni del cluster.

![[Pasted image 20241211150027.png]]


### 2.  Installazione del Metrics Server
Se stai usando **Minikube**, l’installazione è semplicissima: ti basta eseguire il comando:

```bash
minikube addons enable metrics-server
```


Per altri ambienti, invece, devi:
1. Clonare i file di deployment del Metrics Server dal repository ufficiale su GitHub.

```bash
git clone https://github.com/kubernetes-incubator/metrics-serve
```

2. Eseguire il comando

```bash
kubectl create -f <file_deployment>
```

Questo comando distribuisce i pod, i servizi e i ruoli necessari per il corretto funzionamento del Metrics Server.

Dopo l'installazione, dai al Metrics Server qualche minuto per raccogliere e aggregare i dati.



### 3. Visualizzare le metriche - COMANDI
Una volta che il Metrics Server è operativo, puoi iniziare a vedere i dati relativi alle prestazioni del tuo cluster con semplici comandi:


1. **Verificare le metriche sui nodi**:   
   ```bash
kubectl top node
```

Questo comando ti mostrerà il consumo di CPU e memoria per ciascun nodo.

![[Pasted image 20241211150245.png]]



2. **Verificare le metriche sui pod**:   
   ```bash
kubectl top pod
```

Qui potrai vedere il consumo di risorse per ogni pod in esecuzione nel cluster.

![[Pasted image 20241211150258.png]]