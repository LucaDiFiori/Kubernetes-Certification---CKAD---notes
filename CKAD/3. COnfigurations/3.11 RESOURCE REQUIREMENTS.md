Immaginiamo un cluster composto da tre nodi, ciascuno con una determinata quantità di risorse CPU e memoria a disposizione. Ogni pod richiede un insieme specifico di risorse per funzionare correttamente.

Quando un pod viene schedulato su un nodo, consuma una parte delle risorse disponibili su quel nodo.

Il **kube-scheduler** è responsabile di decidere su quale nodo posizionare un pod. Questa decisione si basa sulle risorse richieste dal pod, confrontandole con quelle disponibili su ciascun nodo. L'obiettivo è individuare il nodo più adatto per ospitare il pod.

Se le risorse per ogni nodo risultatno esaurite, lo scheduler sospenderà l'assegnazione del nodo mettendono in stato di **pending**
Usando il comando `describe`, sotto la sezione `events`, si noterà che la motivazione sarà, ad esempio, `Insufficient cpu`


## Resource Request per un container
La **resource request** di un container rappresenta la quantità minima di risorse (CPU e memoria) che il container richiede per funzionare correttamente ed essere creato.

Quando viene definita una resource request:

- **CPU**: è espressa in unità di CPU (ad esempio, 500m per mezzo core) e garantisce che il container avrà sempre a disposizione almeno quella quantità di potenza di calcolo.
- **Memoria**: è espressa in byte (ad esempio, 256Mi) e garantisce che il container avrà sempre accesso almeno a quella quantità di memoria.

#### Resource Requesto attraverso fie-definition
Per specificare le quantità minime per la creazione di un pod basta aggiungere , sotto `spec` , il campo **`resources.requests`** e specificare i valori desiderati

**--> `spec.containers[].resources.requests`**

![[Pasted image 20241202104148.png]]


***

## Rerource - CPU
Ma cosa significa in realtà "un unità di CPU"?

E' possibile specificare qualsiasi valore partendo da un minimo di 0.1
Questa quantità può anche essere espressa come `100m` (con m = milli),
ed è quindi possibile scendere fino a:

- **Quantità minima di CPU**:  1m

Kubernetes astrae l'unità di misura della CPU per uniformare la gestione delle risorse, indipendentemente dall'infrastruttura sottostante.

In Kubernetes, **1 unità di CPU** rappresenta una CPU virtuale, ma il significato preciso varia in base al fornitore di cloud o al sistema di virtualizzazione utilizzato:

- **AWS**: 1 unità di CPU equivale a una vCPU (virtual CPU). In AWS, una vCPU corrisponde a un thread fisico su un core di un processore multi-thread (ad esempio, in un'istanza EC2).
- **Google Cloud Platform (GCP)**: 1 unità di CPU equivale a un core fisico di una CPU virtuale. In GCP, una CPU virtuale è progettata per essere equivalente a un core hardware.
- **Azure**: 1 unità di CPU corrisponde a un core virtuale, che funziona in modo simile alle altre piattaforme cloud.
- **Sistemi con hyperthreading**: 1 unità di CPU equivale a un thread logico su un core fisico. Gli hyperthread sono una tecnologia di CPU che consente a ogni core fisico di eseguire due thread simultaneamente.

In pratica, questa astrazione semplifica l'utilizzo delle risorse nel cluster Kubernetes, permettendo di definire richieste e limiti di CPU senza doversi preoccupare dei dettagli specifici dell'hardware o del cloud provider.

![[Pasted image 20241202110430.png]]


## Rerource - MEMORY
notazioni per specificare la memoria:
![[Pasted image 20241202110603.png]]



***
## Resource Limits
Esaminiamo ora un container in esecuzione su un nodo.

--> **NOTA**: **Per impostazioni predefinita, un container non ha limiti alle risorse che può consumare su un nodo!**

Tuttavia, è possibile impostare un limite per l'utilizzo delle risorse.
Per farlo possiamo aggiungere il campo `resource.limits` specificando il tipo di risorse ed il suo limite 

**--> `spec.containers[].resources.limits`**


![[Pasted image 20241202111215.png]]


### Exceed Limits
Cosa succede quando un pod cerca di superare le risorse?

####  Superamento Limite CPU
**Throttling della CPU**:
- Quando un container nel Pod cerca di utilizzare più CPU di quanto specificato nei limiti (`resources.limits.cpu`), Kubernetes applica un **throttling**.

- Questo significa che il sistema **riduce** l'accesso del container alla CPU per mantenerlo entro i limiti impostati. Non viene ucciso, ma la sua capacità di utilizzare risorse CPU viene limitata.


#### Superamento Limite di Memoria
- **Comportamento del Container**:
	- A differenza della CPU, un container può inizialmente utilizzare più memoria di quanto specificato nei limiti (`resources.limits.memory`). Tuttavia, se il container continua a consumare memoria oltre il limite impostato, il sistema deve intervenire.

- **OOMKill (Out of Memory Kill)**:
    - Se un container supera costantemente il limite di memoria, Kubernetes rileva questa condizione e attua un meccanismo di protezione chiamato **OOM Killer**. Questo è un processo del kernel Linux che uccide i processi che consumano troppa memoria per liberare risorse e prevenire il crash dell'intero nodo.
    - Quando il nodo Kubernetes uccide un container a causa di un superamento del limite di memoria, si verifica un evento noto come **OOMKill**.
      
3. **Log dell'Errore**:
    - Quando un container viene ucciso per superamento della memoria, puoi trovare un errore nei log del container che indica che il sistema ha eseguito l'OOMKill. Questo errore di tipo **OOM** (out of memory) è un segnale chiaro che il container ha esaurito le risorse di memoria disponibili.



***
## Gestione delle Risorse in Kubernetes: Default Behavior

- **Nessuna Richiesta o Limite Preimpostati**:
  
    - Per impostazione predefinita, se non specificato diversamente, un Pod in Kubernetes non ha richieste di CPU o limiti di memoria. Questo significa che non ci sono vincoli sull'uso delle risorse da parte dei container all'interno del Pod.
      
- **Consumo Illimitato di Risorse**:
    
    - Senza richieste o limiti definiti, un Pod potrebbe teoricamente utilizzare tutte le risorse disponibili su un nodo. Questo può portare a una situazione in cui il Pod consuma tutte le risorse CPU o memoria disponibili, influenzando negativamente le prestazioni di altri Pod in esecuzione sullo stesso nodo.


## Behavior -CPU
Vediamo come funzionano le richieste e i limiti della CPU.

Supponiamo di avere due pod (nota: in questo contesto, consideriamo un container all'interno di ciascun pod) in competizione per le risorse CPU disponibili nel cluster.

Se non vengono impostati limiti per la CPU, un pod potrebbe consumare tutte le risorse disponibili, impedendo al secondo di ottenere la quantità di CPU necessaria per funzionare correttamente.

L'impostazione di **limiti** aiuta a garantire un'allocazione equa delle risorse tra i pod, evitando che uno monopolizzi la CPU a discapito degli altri.

Vediamo i vari scenari possibili:
#### No Request - No Limits
Senza impostare request o limits, uno dei pod potrebbe consumare tutte le risosrse disponibili non lasciandone al secondo pod
![[Pasted image 20241202113838.png]]


#### No Request - Limits
Nello scenario in cui non vengano imposti solo i limits per la CPU ma non le request, 

**-->** In questo caso **Kubernetes setta automaticamente la request uguale al limit**

![[Pasted image 20241202114312.png]]



#### Request - Limits
Nel caso in cui vengano impostate sia la request che il limit

Sebbene i limiti della CPU garantiscano un'allocazione equa delle risorse, possono introdurre una limitazione indesiderata in determinati scenari.

Ad esempio, supponiamo che il pod 1 necessiti di più cicli CPU, ma il pod 2 non stia utilizzando una quantità significativa di risorse in quel momento. In questa situazione, non sarebbe ideale limitare il consumo di CPU del pod 1, poiché ci sono risorse inutilizzate che potrebbero essere sfruttate.

![[Pasted image 20241202114911.png]]



#### Request - NO Limits (migliore)
Un approccio più flessibile consiste nell'utilizzare le **resource requests** senza impostare limiti rigidi. 

Questo consente al pod 1, ad esempio, di consumare più CPU quando il pod 2 non ne ha bisogno. Tuttavia, nel momento in cui il pod 2 richiede risorse, il sistema assicura che entrambi i pod abbiano accesso almeno alla quantità di CPU specificata nelle rispettive richieste.


Impostando solo le **requests** senza configurare i **limits**, ogni pod avrà garantita una quantità minima di CPU. Tuttavia, poiché i limiti non sono definiti, qualsiasi pod potrà utilizzare tutti i cicli CPU disponibili quando non sono richiesti dagli altri.

In qualsiasi momento, se gli altri pod necessitano di più cicli CPU, il sistema garantirà loro almeno la quantità minima di risorse definita dalle rispettive requests. Questo approccio consente un uso più flessibile ed efficiente delle risorse disponibili nel cluster.

![[Pasted image 20241202115250.png]]






## Behavior - MEMORY
Vediamo ora il comportamento per la risorsa memory
#### No Request - No Limits
Analogamente alla CPU, se non vengono impostate request o limits, una delle risorse sul nodo potrebbe consumarla tutta a discapito delle altre

#### No Request - Limits
Nel caso in cui non vengano impostati solo i limits

**--> Kubernetes imposta automaticamente la request uguale al limt**


#### Request - Limits
In questo scenario ogni pod vede garantità una certa quantità di momoria e può salire fino al limite imposto.


#### Request - NO Limits (migliore)
Quando si assegna una **request** per la memoria, ma non si definisce un **limit**, Kubernetes si comporta in modo diverso rispetto alla CPU, poiché la memoria è una risorsa **non comprimibile**.

- La **request** assicura che il pod abbia sempre accesso almeno alla quantità di memoria specificata. Questo significa che il kube-scheduler posizionerà il pod solo su nodi che abbiano sufficiente memoria disponibile per soddisfare la request.

-  Senza un **limit**, il container può utilizzare memoria oltre la request, fino a quando il nodo ha risorse disponibili. Non ci sono vincoli espliciti sul consumo massimo di memoria, il che può portare a un utilizzo flessibile delle risorse

-  Se il container utilizza più memoria di quella disponibile sul nodo e causa esaurimento delle risorse (Out of Memory, OOM), il kernel del sistema operativo potrebbe terminare il container per liberare memoria. Questo evento è noto come **OOMKill (Out of Memory Kill)**.

Cioè: Una volta assegnata la memoria questa rimane allocata. Nel caso in cui uno dei pod dovesse richiederne altra, l'unica soluzione sarà uccidere il pod e recuperarla



***
## LimitRange
Per impostazione predefinita, Kubernetes non assegna automaticamente **requests** o **limits** alle risorse di un pod. Tuttavia, possiamo garantire che ogni pod creato in un namespace abbia un set predefinito di requests e limits utilizzando una risorsa chiamata **LimitRange**.

### **Cos'è un LimitRange?**
Un **LimitRange** è un oggetto di configurazione di Kubernetes che impone restrizioni sulle risorse utilizzabili da un pod o da un container all'interno di un namespace. Con un LimitRange, è possibile:

1. **Definire valori predefiniti**: Se un pod o un container non specifica esplicitamente i propri requests o limits, Kubernetes applicherà i valori predefiniti definiti nel LimitRange.
2. **Imporre limiti minimi e massimi**: È possibile stabilire i valori minimi e massimi che possono essere richiesti o limitati da un container o pod.
3. **Regolare la densità dei pod**: Evita che un container utilizzi più risorse del previsto o che un pod non specifichi alcuna richiesta minima.


- I limitRange aiutatno a definire i valori predefiniti da impostare per i container nei pod, senza una richiesta o un limite specificato.

- Si applicano **a livello di namespace**

#### Limit range: MEMORY
![[Pasted image 20241202121014.png]]


#### Limit range: CPU
![[Pasted image 20241202121202.png]]




***
## Resource Quotas

Per **limitare la quantità totale di risorse** che possono essere consumate dalle applicazioni distribuite nel cluster
(es: tutti i pod non devono consumare più di una certa quantità di CPU o Memory), possiamo creare una **resource quota a livello di namespace**


Una **ResourceQuota** è un oggetto di configurazione in Kubernetes che limita il consumo complessivo delle risorse in un namespace. Essa consente di definire quante risorse possono essere utilizzate da tutti i pod e i container all'interno di quel namespace.

La **ResourceQuota** specifica le quantità massime di risorse, come CPU e memoria, che possono essere richieste (requests) e limitate (limits) dai pod e dai container in un dato namespace. In questo modo, è possibile gestire e controllare le risorse a disposizione, evitando che un singolo team o applicazione consumi tutte le risorse del cluster.

![[Pasted image 20241202121629.png]]